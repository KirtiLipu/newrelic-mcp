import os
import requests
import argparse
from typing import Any, Dict, List
from datetime import datetime, timedelta, timezone
from mcp.server.fastmcp import FastMCP
from dotenv import load_dotenv
import logging
from litellm import acompletion

# Parse command line arguments
parser = argparse.ArgumentParser(description='New Relic MCP Server')
parser.add_argument('--new-relic-api-key', required=True, help='New Relic API Key')
parser.add_argument('--nr-insights-api-key', required=True, help='New Relic Insights API Key')
parser.add_argument('--new-relic-account-id', required=True, help='New Relic Account ID')
parser.add_argument('--model', required=True, help='Model to use for LLM calls for find proper app id')
args = parser.parse_args()


# New Relic API configuration
NEW_RELIC_API_KEY = args.new_relic_api_key
NEW_RELIC_ACCOUNT_ID = args.new_relic_account_id
NR_API_BASE = "https://api.newrelic.com/v2"
NR_INSIGHTS_API_BASE = "https://insights-api.newrelic.com/v1"
NR_INSIGHTS_API_KEY = args.nr_insights_api_key
DEFAULT_METRIC_VALUES = ['average_response_time', 'calls_per_minute', 'apdex_score', 'error_rate']


logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger('newrelic_mcp')

if not NEW_RELIC_API_KEY:
    raise ValueError("NEW_RELIC_API_KEY must be provided as a command line argument.")
if not NEW_RELIC_ACCOUNT_ID:
    raise ValueError("NEW_RELIC_ACCOUNT_ID must be provided as a command line argument.")
if not NR_INSIGHTS_API_KEY:
    raise ValueError("NR_INSIGHTS_API_KEY must be provided as a command line argument.")

_newrelic_applications_available = None

def _initialize_newrelic_data():
    """
    Initialize New Relic data by fetching all applications and their IDs.
    Returns a list of dictionaries containing application names and IDs.
    """
    headers = {
        'X-Api-Key': NEW_RELIC_API_KEY
    }
    
    try:
        # Call New Relic API to get all applications
        response = requests.get(
            f"{NR_API_BASE}/applications.json",
            headers=headers
        )
        response.raise_for_status()
        
        applications = response.json().get('applications', [])
        
        # Extract relevant information
        _newrelic_applications_available = [
            {
                "app_id": str(app['id']),
                "name": app['name']
            }
            for app in applications
        ]
        
        logger.info(f"Retrieved {len(_newrelic_applications_available)} applications from New Relic")
        return _newrelic_applications_available
        
    except requests.exceptions.RequestException as e:
        logger.error(f"Error fetching applications from New Relic: {str(e)}")
        return []


# Cache for application ID lookups
_application_id_cache = {}

async def find_newrelic_application_id(application_name: str):
    # Check cache first
    if application_name in _application_id_cache:
        return _application_id_cache[application_name]
        
    system_prompt = f"""
    Find the application id that best matches the application name "{application_name}" from the list of applications:
    The list of applications available are:
    {_newrelic_applications_available}

    You must return only the application id. No extra text or explanation.

    """
    logger.info(f"Finding application id for {application_name}")
    logger.info(f"API Key: {NEW_RELIC_API_KEY}")
    response = await acompletion(
        model=args.model,
        messages=[{"role": "system", "content": system_prompt}],
    )
    app_id = response.choices[0].message.content
    logger.info(f"Application id for {application_name} is {app_id}")
    
    # Cache the result
    _application_id_cache[application_name] = app_id
    
    return app_id
    

apm_metrics_available = [
    "HttpDispatcher",
    "Apdex"
]

# Create MCP server
mcp = FastMCP("newrelic-mcp")

class NewRelicClient:
    def __init__(self):
        self.headers = {
            "X-Api-Key": NEW_RELIC_API_KEY,
            "Content-Type": "application/json"
        }
        self.insights_headers = {
            "X-Query-Key": NR_INSIGHTS_API_KEY,
            "Content-Type": "application/json"
        }
        if not NEW_RELIC_API_KEY:
            logger.warning("NEW_RELIC_API_KEY environment variable not set.")

    def _make_request(self, endpoint, params=None, data=None, method="GET"):
        if not self.headers.get("X-Api-Key"):
            logger.error("Cannot make New Relic API request: API key is missing.")
            return {"error": "New Relic API key not configured"}
            
        try:
            full_url = f"{NR_API_BASE}/{endpoint}"
            logger.debug(f"Making New Relic request to: {full_url} with params: {params}")
            response = requests.request(
                method,
                full_url,
                headers=self.headers,
                params=params,
                json=data
            )
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            error_message = f"New Relic API request error: {str(e)}"
            if e.response is not None:
                error_message += f" - Response: {e.response.text}"
            logger.error(error_message)
            return {"error": error_message}
        except Exception as e:
            logger.error(f"Unexpected error during New Relic API request: {str(e)}")
            return {"error": f"Unexpected error: {str(e)}"}

    def _make_insights_request(self, query, account_id=None):
        """
        Make a request to the New Relic Insights API using NRQL.
        """
        if not account_id:
            account_id = NEW_RELIC_ACCOUNT_ID

        if not account_id:
            logger.error("NEW_RELIC_ACCOUNT_ID environment variable not set.")
            return {"error": "New Relic Account ID not configured"}

        try:
            url = f"{NR_INSIGHTS_API_BASE}/accounts/{account_id}/query"
            logger.debug(f"Making Insights API request with query: {query}")
            
            response = requests.get(
                url,
                headers=self.insights_headers,
                params={"nrql": query}
            )
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            error_message = f"New Relic Insights API request error: {str(e)}"
            if e.response is not None:
                error_message += f" - Response: {e.response.text}"
            logger.error(error_message)
            return {"error": error_message}
        except Exception as e:
            logger.error(f"Unexpected error during New Relic Insights API request: {str(e)}")
            return {"error": f"Unexpected error: {str(e)}"}

    def get_apm_metrics_names(self, app_id: int):
        """
        Get available APM metrics names for a specific application.
        """
        return self._make_request(
            f"applications/{app_id}/metrics.json"
        )
    
    def get_application_metric_request(self, app_id: int, metric_names: list[str], metric_values: list[str]=None, summarize: bool = True, params: dict = None):
        """Fetch specific APM metric data points for an application using metrics/data.json"""
         
        request_params = params or {
            "names[]": metric_names,
            "values[]": metric_values,
            "summarize": "true" if summarize else "false"
        }

        return self._make_request(
            f"applications/{app_id}/metrics/data.json",
            params=request_params
        )

    def get_slow_transactions(self, app_id: int, time_range_minutes: int = 30):
        """
        Get slow transactions using New Relic Insights API with NRQL.
        """
        query = f"""
        FROM Transaction
        SELECT
          sum(duration) AS 'Total Duration',
          average(duration) * 1000 AS 'Avg Duration',
          min(duration) * 1000 AS 'Min Duration',
          max(duration) * 1000 AS 'Max Duration',
          count(*) AS 'Call Count',
          filter(count(*), WHERE error IS true) * 100 / count(*) AS 'Error Rate (%)',
          rate(count(*), 1 minute) AS 'Throughput (rpm)'
        WHERE appId = {app_id}
        SINCE {time_range_minutes} minutes ago
        FACET name
        ORDER BY `Total Duration` DESC
        LIMIT 5
        """

        result = self._make_insights_request(query)

        if not result or "error" in result:
            logger.error(f"Failed to fetch slow transactions: {result.get('error', 'Unknown error')}")
            return {"error": "Failed to fetch slow transactions"}

        def format_ms(value: float) -> str:
            return f"{int(round(value))} ms"

        slow_transactions = []
        if "facets" in result:
            for facet in result["facets"]:
                try:
                    name_raw = facet["name"]
                    results = facet["results"]


                    avg_ms = float(results[1].get("result", 0))
                    min_ms = float(results[2].get("result", 0))
                    max_ms = float(results[3].get("result", 0))

                    transaction_data = {
                        "name": name_raw,
                        "total_duration": round(float(results[0].get("sum", 0)), 2),
                        "avg_duration": format_ms(avg_ms),
                        "min_duration": format_ms(min_ms),
                        "max_duration": format_ms(max_ms),
                        "call_count": int(results[4].get("count", 0)),
                        "error_rate": round(float(results[5].get("result", 0)), 2),
                        "throughput": round(float(results[6].get("result", 0)), 2)
                    }
                    slow_transactions.append(transaction_data)
                except Exception as e:
                    logger.warning(f"Skipping facet due to error: {e}")

        return {"transactions": slow_transactions}
    
    def get_top_database_operations(self, app_id: int, time_range_minutes: int = 30, limit: int = 5):
        """
        Get top database operations using New Relic Insights API with NRQL.
        """
        query = f"""
        FROM Metric 
        SELECT rate(count(apm.service.datastore.operation.duration), 1 minute) * average(apm.service.datastore.operation.duration * 1000) AS 'Total Time per Minute (ms)',
            average(apm.service.datastore.operation.duration * 1000) AS 'Avg Query Time (ms)',
            rate(count(apm.service.datastore.operation.duration), 1 minute) AS 'Throughput (ops/min)'
        WHERE appId = {app_id} 
        FACET `datastoreType`, `table`, `operation`
        SINCE {time_range_minutes} minutes ago 
        LIMIT {limit}
        """

        result = self._make_insights_request(query)

        if not result or "error" in result:
            logger.error(f"Failed to fetch top database operations: {result.get('error', 'Unknown error')}")
            return {"error": "Failed to fetch top database operations"}

        database_operations = []

        for facet in result.get("facets", []):
            try:
                name_fields = facet.get("name") or facet.get("facet")
                if not name_fields or len(name_fields) != 3:
                    logger.warning(f"Unexpected facet structure: {facet}")
                    continue

                datastore_type, table, operation = name_fields

                total_time = facet["results"][0].get("result", 0.0)
                avg_time = facet["results"][1].get("average", 0.0)
                throughput = facet["results"][2].get("result", 0.0)

                # Check if query time exceeds threshold
                query_latency = float(avg_time) > 8.0
                if query_latency:
                    logger.warning(f"Slow query detected: {operation} on table {table} with avg time {round(float(avg_time), 2)}ms")

                database_operations.append({
                    "datastoreType": datastore_type or "unknown",
                    "table": table or "unknown",
                    "operation": operation or "unknown",
                    "total_time_per_minute": round(float(total_time), 2),
                    "avg_query_time_ms": round(float(avg_time), 2),
                    "throughput_ops_per_min": round(float(throughput), 2),
                    "query_latency": query_latency
                })

            except Exception as e:
                logger.exception(f"Error parsing facet: {facet} - {e}")
                continue


        database_operations.sort(key=lambda x: x["avg_query_time_ms"], reverse=True)

        error_operations = [op for op in database_operations if op["query_latency"]]
        if error_operations:
            logger.warning(f"Found {len(error_operations)} database operations with average query time > 8ms")
        return {"database_operations": database_operations}


nr_client = NewRelicClient()

def get_available_apm_metrics(app_id: int):
    """
    Get available APM metrics names for a specific application.
    """
    metrics_response = nr_client.get_apm_metrics_names(app_id)
    metrics_names = [m["name"] for m in metrics_response.get("metrics", [])]
    return metrics_names

def get_app_metric_data(app_id: str, metric_names: list[str]=None, metric_values: list[str]=None, time_range_minutes: int = 30):
    """
    Get formatted APM metrics using the metrics/data.json endpoint.
    Includes both app-level metrics and slowest transactions if include_transactions is True.
    """
    metric_values = metric_values or DEFAULT_METRIC_VALUES
    metric_names = metric_names or apm_metrics_available

    end_time = datetime.now(timezone.utc)
    start_time = end_time - timedelta(minutes=time_range_minutes)

    params = {
        "names[]": metric_names,
        "values[]": metric_values,
        "summarize": "false",
        "from": start_time.strftime('%Y-%m-%dT%H:%M:%S.%fZ'),
        "to": end_time.strftime('%Y-%m-%dT%H:%M:%S.%fZ')
    }

    result = nr_client.get_application_metric_request(app_id, metric_names, metric_values, summarize=False, params=params)

    if not result or "error" in result:
        error_msg = result.get("error", "Unknown error fetching APM metrics") if result else "Empty response fetching APM metrics"
        return {"error": f"Failed to fetch APM metrics: {error_msg}"}
        
    if "metric_data" not in result or not result["metric_data"].get("metrics"):
        formatted_metrics = {}
        for name in metric_names:
            formatted_metrics[name] = "N/A (No data)" 
        return formatted_metrics

    formatted_metrics = {}
    metrics_found = result["metric_data"]["metrics"]
    for metric in metrics_found:
        metric_name = metric["name"]
        if not metric.get("timeslices"):
            continue
            
        if metric_name not in formatted_metrics:
            formatted_metrics[metric_name] = {}
            
        for timeslice in metric["timeslices"]:
            timestamp = timeslice.get("from")
            values = timeslice.get("values", {})
            
            for value_name, value in values.items():
                if value_name not in formatted_metrics[metric_name]:
                    formatted_metrics[metric_name][value_name] = {
                        'current_value': None,
                        'top_values': [],
                        'sum': 0,
                        'count': 0
                    }
                
                try:
                    float_value = float(value)
                except (TypeError, ValueError):
                    float_value = value
                
                if isinstance(float_value, (int, float)):
                    formatted_metrics[metric_name][value_name]['top_values'].append({
                        'value': round(float_value, 2),
                        'timestamp': timestamp
                    })
                    
                    formatted_metrics[metric_name][value_name]['top_values'].sort(
                        key=lambda x: x['value'],
                        reverse=True
                    )
                    formatted_metrics[metric_name][value_name]['top_values'] = formatted_metrics[metric_name][value_name]['top_values'][:3]
                    
                    formatted_metrics[metric_name][value_name]['sum'] += float_value
                    formatted_metrics[metric_name][value_name]['count'] += 1
                
                formatted_metrics[metric_name][value_name]['current_value'] = round(float_value, 2) if isinstance(float_value, (int, float)) else float_value

    for metric_name in formatted_metrics:
        for value_name in formatted_metrics[metric_name]:
            metric_data = formatted_metrics[metric_name][value_name]
            if metric_data['count'] > 0:
                metric_data['avg_value'] = round(metric_data['sum'] / metric_data['count'], 2)
            else:
                metric_data['avg_value'] = None
            
            del metric_data['sum']
            del metric_data['count']

    return formatted_metrics

def get_top_database_operations_details(app_id: str, time_range_minutes: int = 30):
    # Get top database operations details
    db_operations = nr_client.get_top_database_operations(app_id, time_range_minutes)
    if "error" in db_operations:
        logger.error(f"Failed to fetch database operations: {db_operations['error']}")
    else:
        return db_operations.get("database_operations", [])

def get_transaction_details(app_id: int, transaction_name: str, time_range_minutes: int = 30):
    """
    Get transaction details using NRQL Metric table.
    """
    
    transaction_query = f"""
    FROM Metric 
    SELECT average(convert(apm.service.transaction.duration, unit, 'ms'))  as 'Response time', rate(count(apm.service.transaction.duration), 1 minute) AS 'throughput_per_minute'
    WHERE (appId = {app_id}) 
      AND (metricTimesliceName = '{transaction_name}' OR metricTimesliceName IN (SELECT name FROM Transaction WHERE request.uri LIKE '%{transaction_name}%' LIMIT 1))
    FACET `metricTimesliceName` 
    LIMIT 5 
    SINCE {time_range_minutes} minutes ago 
    UNTIL now
    """
    logger.info(f"Transaction query: {transaction_query}")
    transaction_result = nr_client._make_insights_request(transaction_query)
    transaction_result = transaction_result.get("facets", [])[0]
    return {
        "transaction_name": transaction_result.get("name", None),
        "response_time": transaction_result.get("results", [])[0].get("average", 0),
        "throughput_per_minute": transaction_result.get("results", [])[1].get("result", 0)
    }

def _get_total_transaction_count(app_id: int, transaction_name: str, time_range_minutes: int = 30):
    """
    Get total transaction count for a specific transaction name.
    """
    transaction_total_query = f"""
    FROM Transaction
    SELECT latest(name) as 'transaction_name', count(*) as 'total_count'
    WHERE appId = {app_id}
    AND (name = '{transaction_name}' OR request.uri LIKE '%{transaction_name}%')
    SINCE {time_range_minutes} minutes ago
    """
    
    transaction_total_result = nr_client._make_insights_request(transaction_total_query)
    return transaction_total_result

def get_transaction_breakdown_segments(app_id: int, transaction_name: str, time_range_minutes: int = 30):
    """
    Get breakdown segments for a specific transaction using NRQL Metric table.
    Returns a dictionary containing transaction details and breakdown segments.
    """
    # Get total transaction count
    transaction_total_result = _get_total_transaction_count(app_id, transaction_name, time_range_minutes)
    transaction_name = transaction_total_result.get("results", [{}])[0].get("latest", None)
    total_txn_count = transaction_total_result.get("results", [{}])[1].get("count", 0)
    if total_txn_count == 0:
        logger.warning(f"No transactions found for {transaction_name}")
        total_txn_count = 1 

    # Main query to get segment details
    transaction_breakdown_query = f"""
    FROM Metric
    SELECT 
        average(convert(apm.service.transaction.overview, unit, 'ms')) AS 'avg_time',
        count(apm.service.transaction.overview) AS 'call_count',
        sum(convert(apm.service.transaction.overview, unit, 'ms')) AS 'total_time'
    WHERE (appId = {app_id}) 
        AND (transactionName = '{transaction_name}' 
        OR transactionName IN (SELECT name FROM Transaction 
                             WHERE request.uri LIKE '%{transaction_name}%' LIMIT 1))
    FACET `metricTimesliceName`
    LIMIT 7
    SINCE {time_range_minutes} minutes ago 
    UNTIL now
    """
    logger.info(f"Transaction breakdown query: {transaction_breakdown_query}")

    # Get segment breakdown
    transaction_breakdown_result = nr_client._make_insights_request(transaction_breakdown_query)
    logger.info(f"Transaction breakdown result: {transaction_breakdown_result}")

    if not transaction_breakdown_result or "error" in transaction_breakdown_result:
        logger.error(f"Failed to fetch transaction breakdown: {transaction_breakdown_result.get('error', 'Unknown error')}")
        return {"error": "Failed to fetch transaction breakdown"}

    breakdown_segments = []
    total_time = 0
    logger.info(f"Processing transaction breakdown for {transaction_name}")

    for facet in transaction_breakdown_result.get("facets", []):
        segment_name = facet.get("name")
        results = facet.get("results", [])
        
        if not results or not segment_name:
            continue

        avg_time = float(results[0].get("average", 0))
        call_count = float(results[1].get("count", 0))
        segment_total_time = float(results[2].get("sum", 0))
        
        category = "Function"
        if segment_name.startswith("Datastore/"):
            category = "Database"
        elif segment_name.startswith("External/"):
            category = "External"
        
        avg_calls_per_txn = round(call_count / total_txn_count, 2)
        
        breakdown_segments.append({
            "category": category,
            "segment": segment_name,
            "avg_time_ms": round(avg_time, 2),
            "avg_calls_txn": avg_calls_per_txn,
            "total_time_ms": round(segment_total_time, 2),
            "percentage": 0
        })
        
        total_time += segment_total_time

    # Calculate percentages based on total time
    for segment in breakdown_segments:
        if total_time > 0:
            segment["percentage"] = round((segment["total_time_ms"] / total_time) * 100, 2)

    # Sort segments by percentage in descending order
    breakdown_segments.sort(key=lambda x: x["percentage"], reverse=True)

    return {
        "transaction_name": transaction_name,
        "total_time_ms": round(total_time, 2),
        "total_transaction_count": total_txn_count,
        "segments": breakdown_segments
    }

async def get_top_transactions_with_breakdown(appliction_name: int, time_range_minutes: int = 30):
    """
    Get the top N slow transactions and their breakdown segments using entity GUID for breakdown.
    """
    app_id = await find_newrelic_application_id(appliction_name)
    transactions_result = nr_client.get_slow_transactions(app_id, time_range_minutes)
    if "error" in transactions_result:
        return {"error": transactions_result["error"]}
    
    transactions = transactions_result.get("transactions", [])
    logger.info(f"Found {len(transactions)} transactions")
    
    combined = []
    for txn in transactions:
        txn_name = txn["name"]
        breakdown = get_transaction_breakdown_segments(app_id, txn_name, time_range_minutes)
        
        if "error" in breakdown:
            logger.warning(f"Failed to get breakdown for transaction {txn_name}: {breakdown['error']}")
            continue
            
        combined.append({
            "transaction": {
                "name": txn_name,
                "avg_duration": txn["avg_duration"],
                "min_duration": txn["min_duration"],
                "max_duration": txn["max_duration"],
                "call_count": txn["call_count"],
                "error_rate": txn["error_rate"],
                "throughput": txn["throughput"]
            },
            "breakdown": breakdown.get("segments", []),
            "total_duration_ms": breakdown.get("total_time_ms", 0)
        })

    return {
        "transactions": combined,
        "count": len(combined)
    }


@mcp.tool()
async def get_transaction_details_by_url_path(application_name: str, url_path: str, time_range_minutes: int = 30) -> str:
    """
    Get transaction details from New Relic for a specific transaction or api endpoint in an application.
    application_name: name of the application to get metrics
    url_path: url path of the transaction to get details for or transaction name
    time_range_minutes: time range in minutes to get data

    This tool will return the transaction details and breakdown segments for the url path or transaction name.

    If you want to get the transaction details for a specific transaction name,
    you can use the transaction name or the specific url path.
    e.g. food.food_api:FoodTrackerResource.get_food_tracker_page_config or /api/v1/food_tracker/screen_config
    """
    
    try:
        newrelic_application_id = await find_newrelic_application_id(application_name)
        apm_transaction_details = get_transaction_details(newrelic_application_id, url_path, time_range_minutes)
        apm_transaction_breakdown_segments = get_transaction_breakdown_segments(newrelic_application_id, url_path, time_range_minutes)

        return {
            "apm_transaction_details": apm_transaction_details,
            "apm_transaction_breakdown_segments": apm_transaction_breakdown_segments
        }

    except Exception as e:
        logger.error(f"Error fetching New Relic APM metrics: {str(e)}")
        return f"Error fetching New Relic APM metrics: {str(e)}"

@mcp.tool()
async def get_application_metrics(application_name: str, time_range_minutes: int = 30) -> str:
    """
    Get APM metrics from New Relic for a specific application.
    application_name: name of the application to get metrics for
    time_range_minutes: time range in minutes to get data

    Use this function to get metric for entire application including 
        slow transactions, database operations.
    """
    metric_values = DEFAULT_METRIC_VALUES
    
    try:
        newrelic_application_id = await find_newrelic_application_id(application_name)
        metrics_data = get_app_metric_data(newrelic_application_id, apm_metrics_available, metric_values, time_range_minutes)
        slow_transactions = get_top_transactions_with_breakdown(newrelic_application_id, time_range_minutes)
        top_database_operations = get_top_database_operations_details(newrelic_application_id, time_range_minutes)
        return {
            "metrics_data": metrics_data,
            "slow_transactions": slow_transactions,
            "top_database_operations": top_database_operations
        }
    except Exception as e:
        logger.error(f"Error fetching New Relic APM metrics: {str(e)}")
        return f"Error fetching New Relic APM metrics: {str(e)}"

if __name__ == "__main__":
    _newrelic_applications_available = _initialize_newrelic_data()
    mcp.run(transport="stdio")